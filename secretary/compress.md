ğŸš€ Zstd (Zstandard) in Golang

Zstandard (Zstd) is a fast compression algorithm that provides better compression ratios than gzip while being faster. Itâ€™s great for high-performance databases, logs, network transmission, and storage.

ğŸ“Œ Why Use Zstd in Golang?
	â€¢	ğŸ”¥ High compression ratio (better than gzip)
	â€¢	âš¡ Fast decompression (ideal for real-time applications)
	â€¢	ğŸ“‰ Adjustable compression levels (trade-off between speed & compression)
	â€¢	ğŸ”„ Streaming support (works well for large files)

ğŸ“¦ Install Zstd for Golang

Use the optimized Zstd package by Klaus Post:

go get github.com/klauspost/compress/zstd



â¸»

âœï¸ Example: Compress & Decompress Using Zstd

package main

import (
	"bytes"
	"fmt"
	"io"
	"log"

	"github.com/klauspost/compress/zstd"
)

// Compresses input data using Zstd
func compress(data []byte) []byte {
	var buf bytes.Buffer
	writer, _ := zstd.NewWriter(&buf)
	writer.Write(data)
	writer.Close()
	return buf.Bytes()
}

// Decompresses Zstd compressed data
func decompress(compressed []byte) []byte {
	reader, _ := zstd.NewReader(bytes.NewReader(compressed))
	decompressed, _ := io.ReadAll(reader)
	return decompressed
}

func main() {
	data := []byte("Hello, this is a repeated text. Hello, this is a repeated text. Hello, this is a repeated text.")

	// Compress data
	compressed := compress(data)
	fmt.Println("Original Size:", len(data))
	fmt.Println("Compressed Size:", len(compressed))

	// Decompress data
	decompressed := decompress(compressed)
	fmt.Println("Decompressed:", string(decompressed))
}



â¸»

ğŸ“Š How Much Can Zstd Compress?

Zstd compression depends on the data type. Hereâ€™s a rough estimate:

Data Type	Compression Ratio
Text (logs, JSON)	70-85% smaller
Binary (executables, data)	15-40% smaller
Already Compressed Data (JPEG, MP3, MP4)	~0%

	â€¢	Level 1 (fastest) â†’ Lower compression, high speed.
	â€¢	Level 22 (slowest) â†’ Best compression, slow speed.
	â€¢	Default level is 3, which is a good balance.

ğŸš€ Streaming Compression (for Large Data)

If youâ€™re dealing with large files, use streaming compression to avoid excessive memory usage:

func streamCompress(reader io.Reader, writer io.Writer) error {
	zstdWriter, _ := zstd.NewWriter(writer)
	_, err := io.Copy(zstdWriter, reader)
	zstdWriter.Close()
	return err
}

This is useful for compressing database logs, network data, and large files without loading everything into memory.

â¸»

âœ… Where Can Zstd Be Useful in Your Projects?
	â€¢	Bitcask: Compress log segments to reduce disk usage.
	â€¢	B+ Tree: Compress index nodes/pages for better storage efficiency.
	â€¢	Kademlia (DHT): Compress large values to save bandwidth.
	â€¢	Gemini Server: Compress responses for faster transmission.

Would you like a benchmark for your specific data in Go? ğŸš€

